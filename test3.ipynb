{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-fucbkiWfUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import array\n",
        "import gzip\n",
        "import os\n",
        "from os import path\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "_DATA = \"/tmp/jax_example_data/\"\n",
        "\n",
        "\n",
        "def _download(url, filename):\n",
        "  \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "  if not path.exists(_DATA):\n",
        "    os.makedirs(_DATA)\n",
        "  out_file = path.join(_DATA, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(\"downloaded {} to {}\".format(url, _DATA))\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
        "  # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "  base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return np.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download(base_url + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "  test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "  test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(permute_train=False):\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "  test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "  test_labels = _one_hot(test_labels, 10)\n",
        "\n",
        "  if permute_train:\n",
        "    perm = np.random.RandomState(0).permutation(train_images.shape[0])\n",
        "    train_images = train_images[perm]\n",
        "    train_labels = train_labels[perm]\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3cjsJzhjkPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eps = 1e-08\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "t = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dCSx8GGX1xC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "7204f306-a585-4c19-ae08-ee88f7e9030e"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "\n",
        "import numpy.random as npr\n",
        "\n",
        "from jax.api import jit, grad\n",
        "from jax.config import config\n",
        "from jax.scipy.special import logsumexp\n",
        "import jax.numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def init_random_params(scale, layer_sizes, rng=npr.RandomState(0)):\n",
        "  return [(scale * rng.randn(m, n), scale * rng.randn(n))\n",
        "          for m, n, in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "def predict(params, inputs):\n",
        "  activations = inputs\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = np.dot(activations, w) + b\n",
        "    activations = np.tanh(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = np.dot(activations, final_w) + final_b\n",
        "  return logits - logsumexp(logits, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -np.mean(np.sum(preds * targets, axis=1))\n",
        "\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
        "  return np.mean(predicted_class == target_class)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  layer_sizes = [784, 1024, 1024, 10]\n",
        "  param_scale = 0.1\n",
        "  step_size = 0.001\n",
        "  num_epochs = 10\n",
        "  batch_size = 128\n",
        "\n",
        "  train_images, train_labels, test_images, test_labels = mnist()\n",
        "  num_train = train_images.shape[0]\n",
        "  num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "  num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "  def data_stream():\n",
        "    rng = npr.RandomState(0)\n",
        "    while True:\n",
        "      perm = rng.permutation(num_train)\n",
        "      for i in range(num_batches):\n",
        "        batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "        yield train_images[batch_idx], train_labels[batch_idx]\n",
        "  batches = data_stream()\n",
        "  \n",
        "\n",
        "  @jit\n",
        "  def update(params, batch):\n",
        "    grads = grad(loss)(params, batch)\n",
        "    global t \n",
        "    t = t+1\n",
        "\n",
        "    return [(w -step_size* ((beta1 * np.zeros_like(w) + (1 - beta1) * dw )/ (1 - beta1**t)) /(np.sqrt( beta2 * np.zeros_like(w) + (1 - beta2) * (dw * dw) / (1 - beta2**t) ) + eps),  b - step_size * db)\n",
        "             for (w, b), (dw, db) in zip(params, grads)]                                    \n",
        "            \n",
        "\n",
        "            \n",
        "\n",
        "  params = init_random_params(param_scale, layer_sizes)\n",
        "  for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    for _ in range(num_batches):\n",
        "      params = update(params, next(batches))\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    train_acc = accuracy(params, (train_images, train_labels))\n",
        "    test_acc = accuracy(params, (test_images, test_labels))\n",
        "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "    print(\"Training set accuracy {}\".format(train_acc))\n",
        "    print(\"Test set accuracy {}\".format(test_acc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 in 17.66 sec\n",
            "Training set accuracy 0.9696333408355713\n",
            "Test set accuracy 0.9614999890327454\n",
            "Epoch 1 in 15.89 sec\n",
            "Training set accuracy 0.9819333553314209\n",
            "Test set accuracy 0.9678999781608582\n",
            "Epoch 2 in 15.91 sec\n",
            "Training set accuracy 0.9883833527565002\n",
            "Test set accuracy 0.9739000201225281\n",
            "Epoch 3 in 15.64 sec\n",
            "Training set accuracy 0.9901000261306763\n",
            "Test set accuracy 0.9746000170707703\n",
            "Epoch 4 in 15.61 sec\n",
            "Training set accuracy 0.9924166798591614\n",
            "Test set accuracy 0.9768999814987183\n",
            "Epoch 5 in 15.53 sec\n",
            "Training set accuracy 0.9956333041191101\n",
            "Test set accuracy 0.9786999821662903\n",
            "Epoch 6 in 15.76 sec\n",
            "Training set accuracy 0.9967333078384399\n",
            "Test set accuracy 0.9789000153541565\n",
            "Epoch 7 in 16.09 sec\n",
            "Training set accuracy 0.9976000189781189\n",
            "Test set accuracy 0.9800999760627747\n",
            "Epoch 8 in 15.77 sec\n",
            "Training set accuracy 0.9962833523750305\n",
            "Test set accuracy 0.9810000061988831\n",
            "Epoch 9 in 15.61 sec\n",
            "Training set accuracy 0.9974166750907898\n",
            "Test set accuracy 0.979200005531311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SST3IAquk_RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}